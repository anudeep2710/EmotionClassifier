# MLproject
In this project, we aim to create a system that can detect human emotions by analyzing  how people speak (through audio) By breaking down audio signals into important features like MFCCS,Chroma MEL, Contrast, and Tonnetz examining words through patterns  we will train models to recognize emotions such as happiness, sadness, neutral and angry. To keep things simple and efficient, we will use four well-known machine learning methods: Support Vector Machines (SVM), Random Forest, Na√Øve Bayes,  K-Nearest Neighbors (KNN) and Decision Tree. The models will be tested on 4 different datasets to ensure they work well across various types of data, with metrics like accuracy and F1-score helping us measure how well the system performs.
Datasets
Ravadness
Crema -d
SAVEE
EMO -DB

